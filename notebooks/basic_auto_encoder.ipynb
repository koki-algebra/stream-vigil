{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from logging.config import dictConfig\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "from yaml import safe_load\n",
    "\n",
    "from streamvigil import ADBenchDataset\n",
    "from streamvigil.detectors import BasicAutoEncoder, BasicDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger\n",
    "with open(\"./logging.yml\", encoding=\"utf-8\") as file:\n",
    "    config = safe_load(file)\n",
    "dictConfig(config)\n",
    "logger = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Detector\n",
    "auto_encoder = BasicAutoEncoder(\n",
    "    encoder_dims=[500, 450, 400, 350, 300, 250],\n",
    "    decoder_dims=[250, 300, 350, 400, 450, 500],\n",
    "    batch_norm=True,\n",
    ")\n",
    "detector = BasicDetector(auto_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "# Load dataset\n",
    "train_data = ADBenchDataset(\n",
    "    \"../data/9_census.npz\",\n",
    "    train=True,\n",
    "    random_state=random_state,\n",
    ")\n",
    "test_data = ADBenchDataset(\n",
    "    \"../data/9_census.npz\",\n",
    "    train=False,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=512)\n",
    "test_loader = DataLoader(test_data, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 17:31:03,106 [INFO] __main__: Start training the model...\n",
      "2024-05-22 17:31:03,107 [INFO] __main__: Epoch: 1\n",
      "2024-05-22 17:31:03,567 [INFO] __main__: Loss: 0.228254\n",
      "2024-05-22 17:31:03,995 [INFO] __main__: Loss: 0.014057\n",
      "2024-05-22 17:31:04,423 [INFO] __main__: Loss: 0.011099\n",
      "2024-05-22 17:31:04,832 [INFO] __main__: Loss: 0.009813\n",
      "2024-05-22 17:31:05,251 [INFO] __main__: Loss: 0.009438\n",
      "2024-05-22 17:31:05,339 [INFO] __main__: Epoch: 2\n",
      "2024-05-22 17:31:05,344 [INFO] __main__: Loss: 0.009452\n",
      "2024-05-22 17:31:05,756 [INFO] __main__: Loss: 0.008942\n",
      "2024-05-22 17:31:06,179 [INFO] __main__: Loss: 0.007667\n",
      "2024-05-22 17:31:06,646 [INFO] __main__: Loss: 0.007233\n",
      "2024-05-22 17:31:07,055 [INFO] __main__: Loss: 0.007206\n",
      "2024-05-22 17:31:07,091 [INFO] __main__: Epoch: 3\n",
      "2024-05-22 17:31:07,096 [INFO] __main__: Loss: 0.007392\n",
      "2024-05-22 17:31:07,511 [INFO] __main__: Loss: 0.007246\n",
      "2024-05-22 17:31:07,920 [INFO] __main__: Loss: 0.006331\n",
      "2024-05-22 17:31:08,397 [INFO] __main__: Loss: 0.006038\n",
      "2024-05-22 17:31:08,810 [INFO] __main__: Loss: 0.006038\n",
      "2024-05-22 17:31:08,847 [INFO] __main__: Epoch: 4\n",
      "2024-05-22 17:31:08,852 [INFO] __main__: Loss: 0.006289\n",
      "2024-05-22 17:31:09,328 [INFO] __main__: Loss: 0.006231\n",
      "2024-05-22 17:31:09,741 [INFO] __main__: Loss: 0.005500\n",
      "2024-05-22 17:31:10,158 [INFO] __main__: Loss: 0.005288\n",
      "2024-05-22 17:31:10,579 [INFO] __main__: Loss: 0.005261\n",
      "2024-05-22 17:31:10,616 [INFO] __main__: Epoch: 5\n",
      "2024-05-22 17:31:10,621 [INFO] __main__: Loss: 0.005562\n",
      "2024-05-22 17:31:11,083 [INFO] __main__: Loss: 0.005551\n",
      "2024-05-22 17:31:11,507 [INFO] __main__: Loss: 0.004907\n",
      "2024-05-22 17:31:11,967 [INFO] __main__: Loss: 0.004743\n",
      "2024-05-22 17:31:12,385 [INFO] __main__: Loss: 0.004700\n",
      "2024-05-22 17:31:12,427 [INFO] __main__: Epoch: 6\n",
      "2024-05-22 17:31:12,432 [INFO] __main__: Loss: 0.005054\n",
      "2024-05-22 17:31:12,846 [INFO] __main__: Loss: 0.005070\n",
      "2024-05-22 17:31:13,259 [INFO] __main__: Loss: 0.004495\n",
      "2024-05-22 17:31:13,732 [INFO] __main__: Loss: 0.004378\n",
      "2024-05-22 17:31:14,145 [INFO] __main__: Loss: 0.004340\n",
      "2024-05-22 17:31:14,184 [INFO] __main__: Epoch: 7\n",
      "2024-05-22 17:31:14,189 [INFO] __main__: Loss: 0.004602\n",
      "2024-05-22 17:31:14,661 [INFO] __main__: Loss: 0.004704\n",
      "2024-05-22 17:31:15,074 [INFO] __main__: Loss: 0.004147\n",
      "2024-05-22 17:31:15,495 [INFO] __main__: Loss: 0.004060\n",
      "2024-05-22 17:31:15,911 [INFO] __main__: Loss: 0.004048\n",
      "2024-05-22 17:31:15,948 [INFO] __main__: Epoch: 8\n",
      "2024-05-22 17:31:15,953 [INFO] __main__: Loss: 0.004301\n",
      "2024-05-22 17:31:16,422 [INFO] __main__: Loss: 0.004394\n",
      "2024-05-22 17:31:16,848 [INFO] __main__: Loss: 0.003894\n",
      "2024-05-22 17:31:17,315 [INFO] __main__: Loss: 0.003803\n",
      "2024-05-22 17:31:17,732 [INFO] __main__: Loss: 0.003784\n",
      "2024-05-22 17:31:17,769 [INFO] __main__: Epoch: 9\n",
      "2024-05-22 17:31:17,774 [INFO] __main__: Loss: 0.004076\n",
      "2024-05-22 17:31:18,188 [INFO] __main__: Loss: 0.004126\n",
      "2024-05-22 17:31:18,607 [INFO] __main__: Loss: 0.003637\n",
      "2024-05-22 17:31:19,080 [INFO] __main__: Loss: 0.003570\n",
      "2024-05-22 17:31:19,502 [INFO] __main__: Loss: 0.003586\n",
      "2024-05-22 17:31:19,539 [INFO] __main__: Epoch: 10\n",
      "2024-05-22 17:31:19,544 [INFO] __main__: Loss: 0.003800\n",
      "2024-05-22 17:31:20,007 [INFO] __main__: Loss: 0.003894\n",
      "2024-05-22 17:31:20,423 [INFO] __main__: Loss: 0.003455\n",
      "2024-05-22 17:31:20,853 [INFO] __main__: Loss: 0.003427\n",
      "2024-05-22 17:31:21,267 [INFO] __main__: Loss: 0.003413\n",
      "2024-05-22 17:31:21,304 [INFO] __main__: Completed training the model!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 10\n",
    "logger.info(\"Start training the model...\")\n",
    "for epoch in range(epochs):\n",
    "    logger.info(f\"Epoch: {epoch+1}\")\n",
    "    for batch, (X, _) in enumerate(train_loader):\n",
    "        loss = detector.train(X)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            logger.info(f\"Loss: {loss.item():>7f}\")\n",
    "logger.info(\"Completed training the model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 17:31:21,310 [INFO] __main__: Start evaluating the model...\n",
      "2024-05-22 17:31:22,000 [INFO] __main__: AUROC Score: 0.6405672835707877\n",
      "2024-05-22 17:31:22,001 [INFO] __main__: Completed the evaluation of the model!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "metrics = BinaryAUROC()\n",
    "logger.info(\"Start evaluating the model...\")\n",
    "\n",
    "for X, y in test_loader:\n",
    "    scores = detector.predict(X)\n",
    "    metrics.update(scores, y)\n",
    "\n",
    "# Compute AUROC score   \n",
    "logger.info(f\"AUROC Score: {metrics.compute()}\")\n",
    "\n",
    "logger.info(\"Completed the evaluation of the model!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
